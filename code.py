# -*- coding: utf-8 -*-
"""Explainable ML_2_interpretation Challenges.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1keWVstyIo3l72MSADconnNTVRXvsXP1b

Q-What is the difference between Regression and Classification?
A-Regression involves predicting continuous numerical values based on input features. Its primary objective is to establish a mathematical relationship between independent variables and a dependent variable, allowing for the estimation or prediction of continuous outcomes. For instance, in predicting house prices, regression models analyze features like square footage, number of bedrooms, location, etc., to estimate the continuous price of a house. Algorithms such as linear regression, decision trees, or neural networks are commonly used for regression tasks. Evaluation of regression models is based on metrics like Mean Squared Error (MSE), Root Mean Squared Error (RMSE), or R-squared to assess the accuracy of predictions.

Classification, on the other hand, deals with predicting categorical labels or class memberships for input data. The main goal is to categorize or classify data into predefined classes or categories. For example, in email spam detection, classification models differentiate between spam and non-spam emails based on features like keywords, sender information, etc. Algorithms such as logistic regression, decision trees, support vector machines, or neural networks are employed for classification tasks. Evaluation metrics for classification include accuracy, precision, recall, F1-score, etc., to measure the model's ability to correctly classify instances into their respective classes.
"""

import pandas as pd

# Replace 'file.csv' with your CSV file name and path
file_path = 'file.csv'

# Read the CSV file using pandas
data = pd.read_csv("/content/aa-delays-2023.csv")

# Print all the features (columns) in the CSV file
print("Features in the CSV file:")
for column in data.columns:
    print(column)

"""Q-The goal is to reduce the cost of flight delay.Which target feature do we choose and why?
A-DEP_DELAY (Departure Delay): This feature represents the delay in departure, which directly impacts the overall schedule of the flight. Reducing departure delays can potentially minimize subsequent delays throughout the flight's journey.

By addressing departure delays, airlines can potentially streamline operations, manage resources better, and minimize the domino effect of delays that follow throughout the flight, ultimately reducing the overall cost associated with flight delays.
"""

import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming 'data' contains your dataset
# Replace 'WEATHER_DELAY' and 'ARR_DELAY' with your column names
X = data['WEATHER_DELAY']  # Independent variable
y = data['ARR_DELAY']  # Dependent variable

# Calculate correlation coefficient
correlation = X.corr(y)
print("Correlation between WEATHER_DELAY and ARR_DELAY:", correlation)

# Scatter plot
plt.scatter(X, y)
plt.xlabel('WEATHER_DELAY')
plt.ylabel('ARR_DELAY')
plt.title('Scatter plot of WEATHER_DELAY vs ARR_DELAY')
plt.show()

# Perform regression analysis
X = sm.add_constant(X)  # Add a constant to the independent variable
model = sm.OLS(y, X).fit()  # Fit the regression model
print(model.summary())  # Print the summary of the regression model

"""Constant (Intercept): The constant term (const) is approximately 3.586. This suggests that when WEATHER_DELAY is zero, the predicted ARR_DELAY is around 3.586.

WEATHER_DELAY: The coefficient for WEATHER_DELAY is approximately 1.141. This indicates that for every unit increase in WEATHER_DELAY, the ARR_DELAY is predicted to increase by approximately 1.141 units.

p-values: Both coefficients (const and WEATHER_DELAY) have very low p-values (close to 0). It suggests that both coefficients are statistically significant in predicting ARR_DELAY. In other words, WEATHER_DELAY has a statistically significant impact on ARR_DELAY.

R-squared: The R-squared value is 0.116, indicating that around 11.6% of the variance in ARR_DELAY can be explained by WEATHER_DELAY in this model. It's a relatively low R-squared value, suggesting that while there's a statistically significant relationship, WEATHER_DELAY alone might not explain all variations in ARR_DELAY
"""

#answer to 6th point
# Drop 'ARR_DELAY' column
data = data.drop('ARR_DELAY', axis=1)

# Filter and drop string columns
string_columns = data.select_dtypes(include='object').columns.tolist()
data = data.drop(columns=string_columns)

# Remaining columns after dropping 'ARR_DELAY' and string columns
print("Remaining columns after deletion:")
print(data.columns)

#answer to 7th point
import pandas as pd

# Assuming 'data' contains your dataset and 'DEP_DELAY' represents departure delay
# Creating a new column 'DELAY_GT_15' indicating delays greater than 15 minutes
data['DELAY_TARGET'] = (data['DEP_DELAY'] > 15).astype(int)

# Displaying the updated dataset with the new column
print(data[['DEP_DELAY', 'DELAY_TARGET']])

#8th point
# Calculate correlations of all features with the target variable
correlations = data.corr()['DELAY_TARGET'].sort_values(ascending=False)

# Display the correlation of features with the target variable
print("Correlation of features with the target variable (DELAY_TARGET):\n")
print(correlations)

"""9th Question
Linear regression has several assumptions that should be met for the model to be reliable and the results to be valid:

1. Linearity:
The relationship between the independent and dependent variables should be linear. This means that changes in the independent variable(s) should result in proportional changes in the dependent variable.

2. Independence:
The residuals (the differences between predicted and actual values) should be independent of each other. In simpler terms, there should be no correlation between the residuals.

3. Homoscedasticity:
The variance of the residuals should be constant across all levels of the independent variables. This implies that the spread of residuals should be consistent along the range of predicted values.

4. Normality:
The residuals should be normally distributed. This assumption indicates that the error terms should follow a normal distribution around the regression line.

5. No multicollinearity:
The independent variables should not be highly correlated with each other. High multicollinearity can affect the model's coefficients and lead to unreliable estimates.

6. No autocorrelation:
There should be no correlation between the residuals at different points in time (for time series data) or across observations. This assumption is essential when dealing with time-related data.

7. Scale and Range:
The variables involved should have a reasonable scale and cover a sufficient range. Extreme values or outliers can significantly impact the results.
"""

#10th point

import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import pandas as pd

# Load or re-import your dataset
data = pd.read_csv('/content/aa-delays-2023.csv')
data['DELAY_TARGET'] = (data['DEP_DELAY'] > 15).astype(int)
# Now 'ARR_DELAY' should be available again in 'data'

# Assuming 'data' contains your dataset
# Extracting ARR_DELAY for the first 100 data points
arr_delay_sample = data['ARR_DELAY'].iloc[:100]

# Kolmogorov-Smirnov test for normality
ks_statistic, p_value = stats.kstest(arr_delay_sample, 'norm')

# Printing the KS test statistic and p-value
print(f"Kolmogorov-Smirnov Test Statistic: {ks_statistic}")
print(f"P-value: {p_value}")

# Plotting histogram of ARR_DELAY
plt.hist(arr_delay_sample, bins=20, edgecolor='black')
plt.xlabel('ARR_DELAY')
plt.ylabel('Frequency')
plt.title('Histogram of ARR_DELAY')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Assuming 'data' contains your dataset
# Extracting ARR_DELAY for the first 100 data points
arr_delay_sample = data['ARR_DELAY'].iloc[:100]

# Apply square root transformation
sqrt_arr_delay = np.sqrt(arr_delay_sample)

# Kolmogorov-Smirnov test for normality after transformation
ks_statistic, p_value = stats.kstest(sqrt_arr_delay, 'norm')

# Printing the KS test statistic and p-value
print(f"Kolmogorov-Smirnov Test Statistic after transformation: {ks_statistic}")
print(f"P-value after transformation: {p_value}")

# Plotting histogram of square root-transformed ARR_DELAY
plt.hist(sqrt_arr_delay, bins=20, edgecolor='black')
plt.xlabel('Square Root-transformed ARR_DELAY')
plt.ylabel('Frequency')
plt.title('Histogram of Square Root-transformed ARR_DELAY')
plt.show()

#11th point


# Assuming 'data' contains your dataset
# Extracting ARR_DELAY for the first 100 data points
arr_delay_sample = data['ARR_DELAY'].iloc[:100]

# Apply logarithmic transformation
log_arr_delay = np.log1p(arr_delay_sample)  # Using log1p to handle zero and negative values

# Kolmogorov-Smirnov test for normality after transformation
ks_statistic, p_value = stats.kstest(log_arr_delay, 'norm')

# Printing the KS test statistic and p-value
print(f"Kolmogorov-Smirnov Test Statistic after transformation: {ks_statistic}")
print(f"P-value after transformation: {p_value}")

# Plotting histogram of log-transformed ARR_DELAY
plt.hist(log_arr_delay, bins=20, edgecolor='black')
plt.xlabel('Log-transformed ARR_DELAY')
plt.ylabel('Frequency')
plt.title('Histogram of Log-transformed ARR_DELAY')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Assuming 'data' contains your dataset
# Extracting ARR_DELAY for the first 100 data points
arr_delay_sample = data['ARR_DELAY'].iloc[:100]

# Shift the data to make it positive (adjust based on your data)
arr_delay_shifted = arr_delay_sample - arr_delay_sample.min() + 1  # Adding 1 to ensure positivity

# Apply logarithmic transformation to shifted data
log_arr_delay = np.log1p(arr_delay_shifted)

# Kolmogorov-Smirnov test for normality after transformation
ks_statistic, p_value = stats.kstest(log_arr_delay, 'norm')

# Printing the KS test statistic and p-value
print(f"Kolmogorov-Smirnov Test Statistic after transformation: {ks_statistic}")
print(f"P-value after transformation: {p_value}")

# Plotting histogram of log-transformed ARR_DELAY
plt.hist(log_arr_delay, bins=20, edgecolor='black')
plt.xlabel('Log-transformed ARR_DELAY')
plt.ylabel('Frequency')
plt.title('Histogram of Log-transformed ARR_DELAY')
plt.show()

"""If the histogram of the log-transformed 'ARR_DELAY' appears more symmetric and bell-shaped and if the Kolmogorov-Smirnov test indicates a higher p-value (closer to 1), it suggests that the transformation has improved the normality of the data. This could imply that the transformed data may be more suitable for analysis that assumes a normal distribution or relies on normality assumptions."""

# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.metrics import accuracy_score, classification_report
# from sklearn.impute import SimpleImputer

# # Assuming 'data' contains your dataset and 'DELAY_TARGET' is the target variable
# # Drop string columns
# string_columns = data.select_dtypes(include='object').columns.tolist()
# data = data.drop(columns=string_columns)

# # Selecting features and target variable
# X = data.drop(columns=['DELAY_TARGET'])  # Features
# y = data['DELAY_TARGET']  # Target variable

# # Splitting the data into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Impute missing values in the dataset
# imputer = SimpleImputer(strategy='mean')  # You can use other strategies as well
# X_train_imputed = imputer.fit_transform(X_train)
# X_test_imputed = imputer.transform(X_test)

# # Creating a decision tree classifier
# clf = DecisionTreeClassifier(random_state=42)

# # Training the decision tree classifier with imputed data
# clf.fit(X_train_imputed, y_train)

# # Making predictions on the test set
# y_pred = clf.predict(X_test_imputed)

# # Evaluating the model
# accuracy = accuracy_score(y_test, y_pred)
# print(f"Accuracy of the decision tree classifier: {accuracy:.2f}")

# # Additional evaluation metrics
# print("\nClassification Report:")
# print(classification_report(y_test, y_pred))

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.impute import SimpleImputer

# Assuming 'data' contains your dataset and 'DELAY_TARGET' is the target variable
# Drop string columns
string_columns = data.select_dtypes(include='object').columns.tolist()
data = data.drop(columns=string_columns)

# List of feature columns (excluding 'DELAY_TARGET')
feature_columns = [
    'OP_CARRIER_FL_NUM', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY',
    'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME',
    'ARR_TIME', 'ARR_DELAY', 'CANCELLED', 'DIVERTED', 'CRS_ELAPSED_TIME',
    'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',
    'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY'
]

# Selecting features and target variable
X = data[feature_columns]  # Features
y = data['DELAY_TARGET']  # Target variable

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Impute missing values in the dataset for all features
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Creating a decision tree classifier
clf = DecisionTreeClassifier(random_state=42)

# Training the decision tree classifier with imputed data
clf.fit(X_train_imputed, y_train)

# Making predictions on the test set
y_pred = clf.predict(X_test_imputed)

# Evaluating the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the decision tree classifier: {accuracy:.2f}")

# Additional evaluation metrics
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import mean_squared_error, r2_score

# Assuming 'y_test' and 'y_pred' are the true and predicted values in a regression scenario
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2) Score: {r2:.2f}")

#13th point
from sklearn.metrics import r2_score

# Assuming 'y_test' and 'y_pred' are the true and predicted values in a classification scenario
r2_classification = r2_score(y_test, y_pred)

print(f"R-squared (R2) Score for Classification: {r2_classification:.2f}")

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import pandas as pd

# Assuming 'data' contains your dataset and 'DELAY_TARGET' is the target variable for regression
# Drop string columns
string_columns = data.select_dtypes(include='object').columns.tolist()
data_regression = data.drop(columns=string_columns)

# Selecting features and target variable for regression
X_regression = data_regression.drop(columns=['DELAY_TARGET'])  # Features
y_regression = data_regression['DELAY_TARGET']  # Target variable

# Splitting the data into training and testing sets for regression
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_regression, y_regression, test_size=0.2, random_state=42)

# Impute missing values in the dataset for regression
imputer_reg = SimpleImputer(strategy='mean')  # You can use other strategies as well
X_train_reg_imputed = imputer_reg.fit_transform(X_train_reg)
X_test_reg_imputed = imputer_reg.transform(X_test_reg)

# Create a dictionary of different regression models
models_regression = {
    'Linear Regression': LinearRegression(),
    'Decision Tree': DecisionTreeRegressor(random_state=42),
    'MLP': MLPRegressor(random_state=42)
}

# Create lists to store metrics for each model
metrics = {
    'Model': [],
    'RMSE Train': [],
    'RMSE Test': [],
    'R2 Score (Test)': []
}

# Training and evaluation code for each regression model
for name, model in models_regression.items():
    model.fit(X_train_reg_imputed, y_train_reg)
    y_train_pred = model.predict(X_train_reg_imputed)
    y_test_pred = model.predict(X_test_reg_imputed)

    rmse_train = mean_squared_error(y_train_reg, y_train_pred, squared=False)
    rmse_test = mean_squared_error(y_test_reg, y_test_pred, squared=False)
    r2 = r2_score(y_test_reg, y_test_pred)

    metrics['Model'].append(name)
    metrics['RMSE Train'].append(rmse_train)
    metrics['RMSE Test'].append(rmse_test)
    metrics['R2 Score (Test)'].append(r2)

# Create a pandas DataFrame from the metrics dictionary
df_metrics = pd.DataFrame(metrics)

# Display metrics as HTML table
html_table = df_metrics.to_html(index=False)
print(html_table)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import r2_score  # For classification, use appropriate metrics like accuracy, precision, recall, etc.
import pandas as pd

# Create lists to store R2 scores for each classifier
metrics_classification = {
    'Model': [],
    'R2 Score (Test)': []
}

# Display classification metrics as HTML table
df_metrics_classification = pd.DataFrame(metrics_classification)
html_table_classification = df_metrics_classification.to_html(index=False)
print(html_table_classification)
# Assuming 'data' contains your dataset and 'DELAY_TARGET' is the target variable for classification
# Drop string columns
string_columns = data.select_dtypes(include='object').columns.tolist()
data_classification = data.drop(columns=string_columns)

# Selecting features and target variable for classification
X_classification = data_classification.drop(columns=['DELAY_TARGET'])  # Features
y_classification = data_classification['DELAY_TARGET']  # Target variable

# Splitting the data into training and testing sets for classification
X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_classification, y_classification, test_size=0.2, random_state=42)

# Impute missing values in the dataset for classification
imputer_clf = SimpleImputer(strategy='mean')  # You can use other strategies as well
X_train_clf_imputed = imputer_clf.fit_transform(X_train_clf)
X_test_clf_imputed = imputer_clf.transform(X_test_clf)

# Create a dictionary of different classification models
models_classification = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42)
}


# Training and evaluation code for each classification model
for name, model in models_classification.items():
    model.fit(X_train_clf_imputed, y_train_clf)
    y_test_pred_clf = model.predict(X_test_clf_imputed)
    r2_clf = r2_score(y_test_clf, y_test_pred_clf)

    metrics_classification['Model'].append(name)
    metrics_classification['R2 Score (Test)'].append(r2_clf)


# Create a pandas DataFrame from the classification metrics dictionary
df_metrics_classification = pd.DataFrame(metrics_classification)

# Display classification metrics as HTML table
html_table_classification

from sklearn.metrics import roc_auc_score, recall_score, f1_score, confusion_matrix
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

# Assuming 'data' contains your dataset and 'DELAY_TARGET' is the target variable for classification
# ... (Previous code remains the same)

# Create an empty dictionary to store metrics for comparison
metrics_classification_compare = {
    'Model': [],
    'AUC': [],
    'Recall': [],
    'F1-score': []
}

# Training and evaluation code for each classification model
for name, model in models_classification.items():
    model.fit(X_train_clf_imputed, y_train_clf)
    y_test_pred_clf = model.predict(X_test_clf_imputed)

    auc = roc_auc_score(y_test_clf, y_test_pred_clf)
    recall = recall_score(y_test_clf, y_test_pred_clf)
    f1 = f1_score(y_test_clf, y_test_pred_clf)

    # Store metrics for comparison
    metrics_classification_compare['Model'].append(name)
    metrics_classification_compare['AUC'].append(auc)
    metrics_classification_compare['Recall'].append(recall)
    metrics_classification_compare['F1-score'].append(f1)

    # Plot ROC Curve
    fpr, tpr, thresholds = roc_curve(y_test_clf, y_test_pred_clf)
    plt.figure()
    plt.plot(fpr, tpr, label=f'ROC Curve - {name} (AUC = {auc:.2f})')
    plt.plot([0, 1], [0, 1], linestyle='--', color='black')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve - {name}')
    plt.legend(loc='lower right')
    plt.show()

    # Confusion Matrix
    cm = confusion_matrix(y_test_clf, y_test_pred_clf)
    print(f"Confusion Matrix - {name}:")
    print(cm)
    print("--------------------------")

# Create a pandas DataFrame from the classification metrics dictionary
df_metrics_classification_compare = pd.DataFrame(metrics_classification_compare)

# Display comparison metrics as HTML table
html_table_classification_compare = df_metrics_classification_compare.to_html(index=False)
print(html_table_classification_compare)

import pandas as pd
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

data = pd.read_csv('/content/aa-delays-2023.csv')

# Filter and drop string columns
string_columns = data.select_dtypes(include='object').columns
data = data.drop(columns=string_columns)

# Assuming 'ARR_DELAY' column exists, create binary classification target variable
data['DELAY_TARGET'] = (data['ARR_DELAY'] > 0).astype(int)

# Selecting numeric features and target variable
X = data.select_dtypes(include=['float64', 'int64']).drop(columns=['ARR_DELAY', 'DELAY_TARGET'])
y = data['DELAY_TARGET']  # Target variable (0: Not delayed, 1: Delayed)

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handling missing values using SimpleImputer
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Creating a decision tree classifier with a depth of 3
clf = DecisionTreeClassifier(max_depth=3, random_state=42)

# Training the decision tree classifier with imputed data
clf.fit(X_train_imputed, y_train)

# Predicting on the test set
y_pred = clf.predict(X_test_imputed)

# Calculating accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the decision tree classifier: {accuracy:.4f}")

# Plotting the decision tree in graphical form
plt.figure(figsize=(10, 6))
plot_tree(clf, feature_names=X.columns, class_names=['Not Delayed', 'Delayed'], filled=True)
plt.title("Decision Tree - Graphical Form (Depth=3)")
plt.show()

# Displaying the decision tree in text form
tree_text = export_text(clf, feature_names=list(X.columns))
print(f"Decision Tree - Text Form (Depth=3):\n{tree_text}")

"""Advantages:
Interpretability: EBMs are designed to be highly interpretable, providing easily understandable explanations for predictions. They offer feature contributions to each prediction, allowing users to understand the impact of individual features.

No Black Box: Unlike some complex models (like neural networks), EBMs are not a black box. They generate easily explainable rules that can be understood and used for decision-making.

Feature Interaction: EBMs naturally capture feature interactions, allowing them to model nonlinear relationships between variables.

Robustness: They are less prone to overfitting compared to some other complex models. The natural regularization inherent in EBMs helps in creating more robust models.

Automatic Feature Selection: EBMs perform automatic feature selection by considering the importance of each feature, which can enhance model generalization.

Disadvantages:
Limited Complexity: EBMs might struggle to capture highly complex relationships in the data compared to more intricate models like deep neural networks or ensemble methods like Random Forests or Gradient Boosting Machines.

Sensitivity to Hyperparameters: Performance might be sensitive to hyperparameters, such as the number of boosting rounds, learning rate, and maximum depth of individual trees.

Computational Cost: Training EBMs can be computationally expensive, especially with large datasets or when complex interactions need to be captured.

Limited Scalability: As with many tree-based models, EBMs might not scale well with extremely high-dimensional datasets due to their ensemble nature and potential computational intensity.

Need for Feature Engineering: While EBMs capture feature interactions, sometimes, extensive feature engineering might be required to ensure optimal performance and interpretability.
"""

!pip install interpret
import pandas as pd
from interpret.glassbox import ExplainableBoostingClassifier
from interpret.perf import ROC
from interpret import show

# Load your flight dataset (replace 'data.csv' with your file name)
data = pd.read_csv('/content/aa-delays-2023.csv')

# Assuming 'ARR_DELAY' column exists, create binary classification target variable
data['DELAY_TARGET'] = (data['ARR_DELAY'] > 0).astype(int)

# Selecting specific features for training
selected_features = ['CRS_DEP_TIME', 'DEP_DELAY', 'TAXI_OUT', 'CRS_ELAPSED_TIME', 'DISTANCE']
X = data[selected_features]  # Features
y = data['DELAY_TARGET']  # Target variable (0: Not delayed, 1: Delayed)

# Splitting the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train an EBM model
ebm = ExplainableBoostingClassifier(random_state=42)
ebm.fit(X_train, y_train)

# Explain global feature importance and interactions
ebm_global_explanation = ebm.explain_global()
show(ebm_global_explanation)

# Plot ROC globally
perf = ROC(ebm.predict_proba).explain_perf(X_test, y_test, name='EBM')
show(perf)

# Explain feature importance and interactions locally for a special dataset
# Replace 'special_dataset' with your actual data subset
# Assuming 'special_dataset' contains the subset of data where you want to explain locally
special_dataset = X_test.head(10)  # Example: Take the first 10 rows for local explanation
local_explanation = ebm.explain_local(special_dataset)
show(local_explanation)